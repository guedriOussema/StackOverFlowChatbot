{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b148674",
   "metadata": {},
   "source": [
    "# 1. Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f5d54cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "241bcd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = pd.read_csv('./data/qs_2016.csv')\n",
    "# answers = pd.read_csv('./data/answ.csv')\n",
    "# tags = pd.read_csv('./data/Tags.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be0e81ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = questions.drop(['Unnamed: 0'], axis=1 )\n",
    "# answers = answers.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba9c1877",
   "metadata": {},
   "outputs": [],
   "source": [
    "words=[]\n",
    "classes = []\n",
    "documents = []\n",
    "ignore_words = ['?', '!']\n",
    "data_file = open('./data/intents.json').read()\n",
    "intents = json.loads(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7709847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tags_list = tags.Tag.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3725d27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor tag in tags_list:\\n    pattern_question = []\\n    questions_tag_ids = tags.loc[tags[\\'Tag\\']==tag].Id.unique()\\n    mask_questions = questions[\"Id\"].isin(questions_tag_ids)\\n    questions_tag = questions.loc[mask_questions]\\n    for index, question in questions_tag.iterrows():\\n        pattern_question.append(question.Title)\\n    a = {\\n    \\'tag\\': tag,\\n    \\'patterns\\': pattern_question,\\n    \\'responses\\': [\"\"],\\n    \\'context\\':[\"\"]\\n    }\\n    intents[\\'intents\\'].append(a)\\n    print(len(intents[\\'intents\\']))\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "for tag in tags_list:\n",
    "    pattern_question = []\n",
    "    questions_tag_ids = tags.loc[tags['Tag']==tag].Id.unique()\n",
    "    mask_questions = questions[\"Id\"].isin(questions_tag_ids)\n",
    "    questions_tag = questions.loc[mask_questions]\n",
    "    for index, question in questions_tag.iterrows():\n",
    "        pattern_question.append(question.Title)\n",
    "    a = {\n",
    "    'tag': tag,\n",
    "    'patterns': pattern_question,\n",
    "    'responses': [\"\"],\n",
    "    'context':[\"\"]\n",
    "    }\n",
    "    intents['intents'].append(a)\n",
    "    print(len(intents['intents']))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02d448b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_sample = questions.sample(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4801b336",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_question=[]\n",
    "for index, question in questions_sample.iterrows():\n",
    "        pattern_question.append(question.Title)\n",
    "        a = {\n",
    "        'tag': 'question',\n",
    "        'patterns': pattern_question,\n",
    "        'responses': [\"\"],\n",
    "        'context':[\"\"]\n",
    "        }\n",
    "        intents['intents'].append(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23c7f50",
   "metadata": {},
   "source": [
    "# 2. Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8276649",
   "metadata": {},
   "outputs": [],
   "source": [
    "for intent in intents['intents']:\n",
    "    for pattern in intent['patterns']:\n",
    "        #tokenize each word\n",
    "        w = nltk.word_tokenize(pattern)\n",
    "        words.extend(w)\n",
    "        #add documents in the corpus\n",
    "        documents.append((w, intent['tag']))\n",
    "        # add to our classes list\n",
    "        if intent['tag'] not in classes:\n",
    "            classes.append(intent['tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13ea94bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40026 documents\n",
      "5 classes ['goodbye', 'greeting', 'options', 'question', 'thanks']\n",
      "884 unique lemmatized words ['#', '&', \"'\", \"''\", \"'access-control-allow-origin\", \"'bind\", \"'d\", \"'defaultindex\", \"'null\", \"'offsetwidth\", \"'s\", '(', ')', '+', ',', '-', '-conf', '.', '.git', '.js', '.srt', '/', '///android_asset/test.html', '/public', '1.9', '10', '104', '15', '2', '2.4', '2015', '2d', '3.0', '404', '5.1', '6', '7', '90', ':', ':drawrects', ';', '<', '>', '``', 'a', 'access', 'access-control-allow-origin', 'according', 'actionresults', 'active', 'ad', 'adc', 'add', 'adding', 'address', 'adloader', 'adwords', 'afnetworking', 'after', 'afternoon', 'aggregation', 'algorithm', 'alignment', 'all', 'allocate', 'allowed', 'always', 'am', 'amazon', 'ammap', 'amount', 'an', 'and', 'android', 'angular', 'angularjs', 'another', 'any', 'anyone', 'api', 'app', 'app.get', 'appearing', 'append', 'appended', 'application', 'apply', 'apps', 'arangodb', 'arcgis', 'architecture', 'are', 'argument', 'armadillo', 'around', 'array', 'arraylist', 'arrow', 'asp.net', 'assetbundle', 'async', 'asynchronously', 'at', 'attribute', 'audio', 'auto', 'auto_increment', 'available', 'avoid', 'awesome', 'aws', 'azure', 'babel', 'background', 'base', 'based', 'be', 'beautify', 'before', 'beginner', 'behave', 'behavior', 'behind', 'being', 'best', 'between', 'bigquery', 'binding', 'block', 'blocking', 'bluemix', 'boolean', 'boot', 'bot', 'bundle', 'but', 'button', 'by', 'bye', 'c', 'c++', 'c++/qt', 'ca', 'cacheable', 'call', 'calling', 'camera', 'can', 'cassette', 'change', 'changing', 'char', 'character', 'chart', 'chatting', 'check', 'checkbox', 'checked', 'choose', 'chr', 'chrome', 'chudnovsky', 'class', 'clear', 'click', 'client', 'close', 'closed', 'closest', 'cloud', 'cluster', 'clustering', 'code', 'collect', 'color', 'column', 'command', 'compare', 'compareto', 'comparison', 'complete', 'completely', 'conditional', 'conditionally', 'configure', 'configuring', 'confirm', 'connect', 'connecting', 'connection', 'connectionsettings', 'console', 'contains', 'content', 'content-based', 'controller', 'conversion', 'cookiejar', 'cooky', 'copy', 'cordova', 'core', 'could', 'create', 'creating', 'credential', 'crlf', 'cs', 'csv', 'current', 'custom', 'customizing', 'data', 'database', 'dataset', 'datastore-identity', 'date', 'datetime', 'day', 'db', 'dbscan', 'deadbolt', 'debug', 'delay/failure', 'delete', 'dependency', 'deployment', 'deprecated', 'derived', 'dev', 'device', 'dexie.js', 'dialog', 'dictionary', 'different', 'differently', 'differing', 'direct', 'directory', 'disability', 'disable', 'display', 'displayed', 'distinct', 'div', 'django', 'dns', 'do', 'documentdb', 'doe', 'doing', 'downloadable', 'draw', 'drive', 'dumping', 'duplicate', 'dynamically', 'dynamodb', 'each', 'efficient', 'element', 'empty', 'emulator', 'encoding', 'end', 'entity', 'equal', 'equivalent', 'error', 'etimedout', 'event', 'excel/vba', 'executereader', 'exist', 'existing', 'expand', 'expected', 'explaining', 'explanation', 'express.js', 'expression', 'expressjs', 'extracting', 'f5', 'f8', 'facade', 'facebook', 'factor', 'fadein', 'failed', 'false', 'feature', 'few', 'field', 'file', 'filewatcher', 'fill', 'filled', 'filter', 'filtering', 'final', 'find', 'find_and_modify', 'finding', 'firefox', 'first', 'fitting', 'fix', 'fixed', 'flume', 'folder', 'for', 'foreach', 'form', 'format', 'formatting', 'found', 'frame', 'freeze', 'from', 'front/rear', 'fs.readfile', 'fsck', 'function', 'functionality', 'functioning', 'gcp', 'gdb', 'geofence', 'get', 'getactivity', 'getting', 'getting/setting', 'ggplot2', 'git', 'github', 'give', 'given', 'gnuplot', 'go', 'going', 'good', 'goodbye', 'google', 'group', 'gulp', 'ha', 'hadoop', 'handle', 'handling', 'happening', 'hasclass', 'hashmap', 'have', 'hdfs', 'he', 'header', 'hello', 'help', 'helpful', 'helping', 'here', 'heroku', 'hex', 'hey', 'hi', 'histogram', 'hola', 'horizontal', 'horn', 'hour', 'how', 'html', 'i', 'id', 'identical', 'identity', 'ie', 'ie11', 'if', 'ignore', 'ignored', 'ikvm', 'image', 'img', 'implementing', 'in', 'include', 'includes', 'including', 'incorrect', 'index', 'indexeddb', 'infinitely', 'information', 'initialization', 'inject', 'inner', 'insertelementat', 'inserting', 'inside', 'installation', 'installed', 'instance', 'instantly', 'int', 'integer', 'intellij', 'intellisense', 'interface', 'intersecting', 'into', 'invalid_grant', 'ip', 'is', 'issue', 'it', 'it/', 'itertools', 'jasmine', 'java', 'javascript', 'javascript/jquery', 'jdo', 'jeditable', 'jersey', 'jinja2', 'job', 'join', 'jquery', 'js/', 'js/css', 'jxls', 'jython', 'key', 'kinect', 'know', 'label', 'lamda', 'large', 'last', 'later', 'layout', 'length', 'let', 'level', 'li', 'library', 'limitation', 'line', 'link', 'linux', 'list', 'load', 'location', 'lock', 'log', 'logic', 'login', 'loop', 'loopback', 'looping', 'love', 'macro', 'main', 'make', 'makemigrations', 'management', 'manager', 'many', 'map', 'matrix', 'may', 'maybe', 'mcl', 'me', 'mean', 'memory', 'message', 'meteor-up', 'method', 'microsoft', 'migration', 'millisecond', 'minimum', 'missing', 'mm', 'mobile', 'mode', 'model', 'modifier', 'monday', 'mongodb', 'mongoid', 'monthly', 'morning', 'move', 'movie', 'msvc', 'multi', 'multi-threading', 'multipart/body', 'multiple', 'mvc', 'my', \"n't\", 'name', 'namenode', 'native', 'nd', 'near', 'nest', 'nested', 'networking', 'new', 'newly', 'next', 'nginx', 'nice', 'no', 'node.js', 'non-english', 'non-ui', 'non-void', 'not', 'null', 'number', 'numpy', 'oauth2client.client.httpaccesstokenrefresherror', 'object', 'occerrence', 'oci', 'ocr', 'of', 'offline', 'oledbconnection', 'on', 'one', 'online', 'only', 'opacity', 'open', 'opengles', 'option', 'or', 'oracle', 'order', 'org.apache.commons.cli.unrecognizedoptionexception', 'organisation', 'origin', 'out', 'output', 'outside', 'overriding', 'own', 'padding', 'page', 'painter', 'pair', 'paper', 'parameter', 'parent', 'parsing', 'part', 'passed', 'path', 'paypal', 'payum', 'pdf', 'pdftk', 'peer', 'pexpect', 'photo', 'php', 'picture', 'pipeline', 'play', 'please', 'plot', 'plotting', 'plug-in', 'poco', 'point', 'polymer', 'port', 'position', 'pouchdb', 'powerpoint', 'practice', 'precision', 'present', 'pretty', 'print', 'problem', 'process', 'product', 'program', 'programatically', 'programming', 'progress', 'project', 'proper', 'property', 'prove', 'provide', 'public-docking-hg', 'pure', 'python', 'qpainter', 'qr-code', 'qt', 'quantity', 'query', 'queue', 'quicktip', 'r', 'raddropdownbutton', 'random', 'range', 'raphael', 'rcpp', 're-apply', 'reachability', 'read', 'real', 'really', 'rearranging', 'reason', 'recording', 'recreates', 'recv', 'red', 'redis', 'reduce', 'reformation', 'region', 'related', 'relation', 'released', 'remove', 'removing', 'rename', 'renew', 'reordering', 'repeating', 'replicated', 'request', 'requested', 'requires', 'reset', 'resource', 'response', 'restangular', 'restful', 'result', 'returning', 'right', 'route', 'router-outlet', 'routing', 'row', 'rpc', 'run', 'running', 'runtime', 'rxswift', 'same', 'sample', 'say', 'screen', 'script', 'sdk', 'search', 'see', 'select', 'selenium', 'self-defined', 'send', 'send/sendline', 'separate', 'seperate', 'serializing', 'server', 'service', 'session', 'set', 'settimeout', 'setting', 'sftp', 'share', 'shared', 'sheet', 'show', 'simple', 'simulate', 'single', 'sitecore', 'size', 'size/position', 'slicing', 'slot', 'slow', 'some', 'someone', 'sometimes', 'source', 'space', 'specific', 'specified', 'split', 'spread', 'spring', 'spwaning', 'spyne', 'sql', 'ssml', 'start', 'started', 'stata', 'state', 'statement', 'static', 'store', 'strategy', 'stream', 'string', 'stripe', 'studio', 'subdomains', 'submatrices', 'submited', 'subscription', 'subset', 'subvectors', 'suggest', 'sunday', 'support', 'svg', 'swift', 'switch', 'sync', 'synchronizationcontext', 'system.invalidoperationexception', 'table', 'tabu', 'tabulating', 'tcp', 'telegram', 'telnet', 'template', 'templating', 'term', 'terminal', 'test', 'text', 'text-inputs', 'text.why', 'thank', 'thanks', 'that', 'the', 'then', 'there', 'therefore', 'these', 'this', 'thread', 'threading', 'three', 'through', 'throughout', 'throwing', 'till', 'time', 'timer', 'timing', 'to', 'toggle', 'tomcat', 'too', 'tool', 'toolbelt', 'torrent', 'total', 'tracking', 'trigger', 'turn', 'twisted', 'twitter', 'two', 'txt', 'type', 'typecasting', 'typeerror', 'typescript', 'typing', 'uberjar', 'ui', 'uibarbuttonitem', 'uibutton', 'uislider', 'uitextfield', 'uitextview', 'ul', 'uncaught', 'undefined', 'under', 'understanding', 'unique', 'unit', 'unix', 'unpack', 'unrecognized', 'update', 'updated', 'updating', 'upload', 'uploads', 'use', 'used', 'user', 'usertoken', 'using', 'utf-8', 'v', 'vaadin', 'value', 'valueerror', 'variable', 'variadic', 'vb', 'vba', 'vector', 'version', 'very', 'video', 'view', 'viewddidload', 'visual', 'vs2013', 'vstest.console', 'wa', 'waiting', 'wallet', 'watch', 'way', 'web', 'webdriver.back', 'webpack', 'webpage', 'webservice', 'website', 'webview.loadurl', 'what', 'when', 'where', 'which', 'while', 'who', 'why', 'wifi', 'winapi', 'winforms.illegalcrossthreadcall', 'with', 'within', 'without', 'word', 'word2vec', 'wordpress', 'work', 'working', 'worksheet_change', 'would', 'write', 'wrong', 'wso2', 'x-by-y', 'xamarin', 'xcode', 'xe', 'year', 'yii2', 'you', 'z3']\n"
     ]
    }
   ],
   "source": [
    "# lemmatize, lower each word and remove duplicates\n",
    "words = [lemmatizer.lemmatize(w.lower()) for w in words if w not in ignore_words]\n",
    "words = sorted(list(set(words)))\n",
    "# sort classes\n",
    "classes = sorted(list(set(classes)))\n",
    "# documents = combination between patterns and intents\n",
    "print (len(documents), \"documents\")\n",
    "# classes = intents\n",
    "print (len(classes), \"classes\", classes)\n",
    "# words = all words, vocabulary\n",
    "print (len(words), \"unique lemmatized words\", words)\n",
    "pickle.dump(words,open('words.pkl','wb'))\n",
    "pickle.dump(classes,open('classes.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abce612b",
   "metadata": {},
   "source": [
    "# 3. Create training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "797accd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-5117620404a0>:22: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  training = np.array(training)\n"
     ]
    }
   ],
   "source": [
    "# create our training data\n",
    "training = []\n",
    "# create an empty array for our output\n",
    "output_empty = [0] * len(classes)\n",
    "# training set, bag of words for each sentence\n",
    "for doc in documents:\n",
    "    # initialize our bag of words\n",
    "    bag = []\n",
    "    # list of tokenized words for the pattern\n",
    "    pattern_words = doc[0]\n",
    "    # lemmatize each word - create base word, in attempt to represent related words\n",
    "    pattern_words = [lemmatizer.lemmatize(word.lower()) for word in pattern_words]\n",
    "    # create our bag of words array with 1, if word match found in current pattern\n",
    "    for w in words:\n",
    "        bag.append(1) if w in pattern_words else bag.append(0)\n",
    "    # output is a '0' for each tag and '1' for current tag (for each pattern)\n",
    "    output_row = list(output_empty)\n",
    "    output_row[classes.index(doc[1])] = 1\n",
    "    training.append([bag, output_row])\n",
    "# shuffle our features and turn into np.array\n",
    "random.shuffle(training)\n",
    "training = np.array(training)\n",
    "# create train and test lists. X - patterns, Y - intents\n",
    "train_x = list(training[:,0])\n",
    "train_y = list(training[:,1])\n",
    "print(\"Training data created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c42f9de",
   "metadata": {},
   "source": [
    "# 4. Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0af29ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c57f5f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guedri/anaconda3/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "8006/8006 [==============================] - 14s 1ms/step - loss: 0.0095 - accuracy: 0.9990\n",
      "Epoch 2/200\n",
      "8006/8006 [==============================] - 11s 1ms/step - loss: 0.0048 - accuracy: 0.9994\n",
      "Epoch 3/200\n",
      "8006/8006 [==============================] - 11s 1ms/step - loss: 0.0037 - accuracy: 0.9994\n",
      "Epoch 4/200\n",
      "8006/8006 [==============================] - 11s 1ms/step - loss: 0.0026 - accuracy: 0.9994\n",
      "Epoch 5/200\n",
      "8006/8006 [==============================] - 11s 1ms/step - loss: 0.0020 - accuracy: 0.9994\n",
      "Epoch 6/200\n",
      "8006/8006 [==============================] - 11s 1ms/step - loss: 0.0015 - accuracy: 0.9994\n",
      "Epoch 7/200\n",
      "8006/8006 [==============================] - 11s 1ms/step - loss: 0.0012 - accuracy: 0.9994\n",
      "Epoch 8/200\n",
      "8006/8006 [==============================] - 11s 1ms/step - loss: 0.0012 - accuracy: 0.9994\n",
      "Epoch 9/200\n",
      "8006/8006 [==============================] - 11s 1ms/step - loss: 0.0011 - accuracy: 0.9996\n",
      "Epoch 10/200\n",
      "8006/8006 [==============================] - 11s 1ms/step - loss: 0.0011 - accuracy: 0.9995\n",
      "Epoch 11/200\n",
      "8006/8006 [==============================] - 11s 1ms/step - loss: 9.8797e-04 - accuracy: 0.9996\n",
      "Epoch 12/200\n",
      "8006/8006 [==============================] - 11s 1ms/step - loss: 9.1993e-04 - accuracy: 0.9996\n",
      "Epoch 13/200\n",
      "8006/8006 [==============================] - 11s 1ms/step - loss: 0.0010 - accuracy: 0.9996\n",
      "Epoch 14/200\n",
      "8006/8006 [==============================] - 11s 1ms/step - loss: 9.8824e-04 - accuracy: 0.9996\n",
      "Epoch 15/200\n",
      "8006/8006 [==============================] - 11s 1ms/step - loss: 8.9766e-04 - accuracy: 0.9997\n",
      "Epoch 16/200\n",
      "8006/8006 [==============================] - 11s 1ms/step - loss: 8.9986e-04 - accuracy: 0.9996\n",
      "Epoch 17/200\n",
      "8006/8006 [==============================] - 11s 1ms/step - loss: 8.2856e-04 - accuracy: 0.9997\n",
      "Epoch 18/200\n",
      "8006/8006 [==============================] - 11s 1ms/step - loss: 9.0974e-04 - accuracy: 0.9997\n",
      "Epoch 19/200\n",
      "8006/8006 [==============================] - 11s 1ms/step - loss: 8.6127e-04 - accuracy: 0.9997\n",
      "Epoch 20/200\n",
      "8006/8006 [==============================] - 11s 1ms/step - loss: 8.6436e-04 - accuracy: 0.9997\n",
      "Epoch 21/200\n",
      "8006/8006 [==============================] - 11s 1ms/step - loss: 8.7234e-04 - accuracy: 0.9997\n",
      "Epoch 22/200\n",
      "8006/8006 [==============================] - 11s 1ms/step - loss: 8.4947e-04 - accuracy: 0.9996\n",
      "Epoch 23/200\n",
      "8006/8006 [==============================] - 11s 1ms/step - loss: 7.8061e-04 - accuracy: 0.9997\n",
      "Epoch 24/200\n",
      "8006/8006 [==============================] - 11s 1ms/step - loss: 8.1445e-04 - accuracy: 0.9997\n",
      "Epoch 25/200\n",
      "8006/8006 [==============================] - 11s 1ms/step - loss: 8.9989e-04 - accuracy: 0.9996\n",
      "Epoch 26/200\n",
      "8006/8006 [==============================] - 11s 1ms/step - loss: 8.1105e-04 - accuracy: 0.9997\n",
      "Epoch 27/200\n",
      "8006/8006 [==============================] - 11s 1ms/step - loss: 8.0771e-04 - accuracy: 0.9997\n",
      "Epoch 28/200\n",
      "8006/8006 [==============================] - 11s 1ms/step - loss: 7.0655e-04 - accuracy: 0.9997\n",
      "Epoch 29/200\n",
      "8006/8006 [==============================] - 12s 1ms/step - loss: 7.1037e-04 - accuracy: 0.9998\n",
      "Epoch 30/200\n",
      "8006/8006 [==============================] - 11s 1ms/step - loss: 6.5229e-04 - accuracy: 0.9998\n",
      "Epoch 31/200\n",
      "8006/8006 [==============================] - 11s 1ms/step - loss: 6.0630e-04 - accuracy: 0.9998\n",
      "Epoch 32/200\n",
      "8006/8006 [==============================] - 11s 1ms/step - loss: 6.6364e-04 - accuracy: 0.9997\n",
      "Epoch 33/200\n",
      "8006/8006 [==============================] - 11s 1ms/step - loss: 5.8024e-04 - accuracy: 0.9998\n",
      "Epoch 34/200\n",
      "8006/8006 [==============================] - 11s 1ms/step - loss: 5.7413e-04 - accuracy: 0.9998\n",
      "Epoch 35/200\n",
      "8006/8006 [==============================] - 11s 1ms/step - loss: 5.7798e-04 - accuracy: 0.9998\n",
      "Epoch 36/200\n",
      "8006/8006 [==============================] - 11s 1ms/step - loss: 6.1664e-04 - accuracy: 0.9998\n",
      "Epoch 37/200\n",
      "8006/8006 [==============================] - 11s 1ms/step - loss: 5.6272e-04 - accuracy: 0.9998\n",
      "Epoch 38/200\n",
      "8006/8006 [==============================] - 11s 1ms/step - loss: 4.9331e-04 - accuracy: 0.9998\n",
      "Epoch 39/200\n",
      "8006/8006 [==============================] - 11s 1ms/step - loss: 5.1995e-04 - accuracy: 0.9998\n",
      "Epoch 40/200\n",
      "8006/8006 [==============================] - 11s 1ms/step - loss: 4.9687e-04 - accuracy: 0.9999\n",
      "Epoch 41/200\n",
      "8006/8006 [==============================] - 11s 1ms/step - loss: 4.6237e-04 - accuracy: 0.9998\n",
      "Epoch 42/200\n",
      "8006/8006 [==============================] - 11s 1ms/step - loss: 4.3975e-04 - accuracy: 0.9999\n",
      "Epoch 43/200\n",
      "8006/8006 [==============================] - 11s 1ms/step - loss: 3.5917e-04 - accuracy: 0.9999\n",
      "Epoch 44/200\n",
      "8006/8006 [==============================] - 11s 1ms/step - loss: 4.6485e-04 - accuracy: 0.9998\n",
      "Epoch 45/200\n",
      "8006/8006 [==============================] - 11s 1ms/step - loss: 4.9994e-04 - accuracy: 0.9998\n",
      "Epoch 46/200\n",
      "8006/8006 [==============================] - 11s 1ms/step - loss: 4.4528e-04 - accuracy: 0.9999\n",
      "Epoch 47/200\n",
      "8006/8006 [==============================] - 11s 1ms/step - loss: 4.7123e-04 - accuracy: 0.9998\n",
      "Epoch 48/200\n",
      "8006/8006 [==============================] - 11s 1ms/step - loss: 4.1073e-04 - accuracy: 0.9999\n",
      "Epoch 49/200\n",
      "8006/8006 [==============================] - 11s 1ms/step - loss: 3.8280e-04 - accuracy: 0.9999\n",
      "Epoch 50/200\n",
      "8006/8006 [==============================] - 11s 1ms/step - loss: 2.4262e-04 - accuracy: 1.0000\n",
      "Epoch 51/200\n",
      "8006/8006 [==============================] - 11s 1ms/step - loss: 2.5250e-04 - accuracy: 1.0000\n",
      "Epoch 52/200\n",
      "8006/8006 [==============================] - 11s 1ms/step - loss: 2.8720e-04 - accuracy: 1.0000\n",
      "Epoch 53/200\n",
      "8006/8006 [==============================] - 12s 1ms/step - loss: 3.5100e-04 - accuracy: 0.9999\n",
      "Epoch 54/200\n",
      "8006/8006 [==============================] - 12s 2ms/step - loss: 2.4143e-04 - accuracy: 1.0000\n",
      "Epoch 55/200\n",
      "8006/8006 [==============================] - 12s 1ms/step - loss: 3.0332e-04 - accuracy: 0.9999\n",
      "Epoch 56/200\n",
      "8006/8006 [==============================] - 12s 2ms/step - loss: 3.6244e-04 - accuracy: 0.9998\n",
      "Epoch 57/200\n",
      "8006/8006 [==============================] - 12s 2ms/step - loss: 2.0856e-04 - accuracy: 0.9999\n",
      "Epoch 58/200\n",
      "8006/8006 [==============================] - 12s 1ms/step - loss: 3.0734e-04 - accuracy: 0.9999\n",
      "Epoch 59/200\n",
      "8006/8006 [==============================] - 12s 1ms/step - loss: 3.3041e-04 - accuracy: 0.9999\n",
      "Epoch 60/200\n",
      "8006/8006 [==============================] - 12s 1ms/step - loss: 1.7060e-04 - accuracy: 1.0000\n",
      "Epoch 61/200\n",
      "8006/8006 [==============================] - 12s 1ms/step - loss: 3.0090e-04 - accuracy: 0.9999\n",
      "Epoch 62/200\n",
      "8006/8006 [==============================] - 13s 2ms/step - loss: 2.2739e-04 - accuracy: 0.9999\n",
      "Epoch 63/200\n",
      "8006/8006 [==============================] - 12s 1ms/step - loss: 2.3933e-04 - accuracy: 0.9999\n",
      "Epoch 64/200\n",
      "8006/8006 [==============================] - 12s 1ms/step - loss: 1.6924e-04 - accuracy: 1.0000\n",
      "Epoch 65/200\n",
      "8006/8006 [==============================] - 13s 2ms/step - loss: 1.9523e-04 - accuracy: 1.0000\n",
      "Epoch 66/200\n",
      "8006/8006 [==============================] - 12s 1ms/step - loss: 1.9824e-04 - accuracy: 0.9999\n",
      "Epoch 67/200\n",
      "8006/8006 [==============================] - 12s 2ms/step - loss: 1.4517e-04 - accuracy: 1.0000\n",
      "Epoch 68/200\n",
      "8006/8006 [==============================] - 12s 2ms/step - loss: 1.8845e-04 - accuracy: 1.0000\n",
      "Epoch 69/200\n",
      "8006/8006 [==============================] - 12s 1ms/step - loss: 1.4401e-04 - accuracy: 1.0000\n",
      "Epoch 70/200\n",
      "8006/8006 [==============================] - 12s 1ms/step - loss: 2.1724e-04 - accuracy: 1.0000\n",
      "Epoch 71/200\n",
      "8006/8006 [==============================] - 12s 2ms/step - loss: 1.3017e-04 - accuracy: 1.0000\n",
      "Epoch 72/200\n",
      "8006/8006 [==============================] - 12s 1ms/step - loss: 2.4519e-04 - accuracy: 0.9999\n",
      "Epoch 73/200\n",
      "8006/8006 [==============================] - 12s 2ms/step - loss: 1.0638e-04 - accuracy: 1.0000\n",
      "Epoch 74/200\n",
      "8006/8006 [==============================] - 12s 1ms/step - loss: 1.7790e-04 - accuracy: 1.0000\n",
      "Epoch 75/200\n",
      "8006/8006 [==============================] - 12s 1ms/step - loss: 1.8458e-04 - accuracy: 1.0000\n",
      "Epoch 76/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8006/8006 [==============================] - 11s 1ms/step - loss: 1.4525e-04 - accuracy: 1.0000\n",
      "Epoch 77/200\n",
      "8006/8006 [==============================] - 11s 1ms/step - loss: 1.7451e-04 - accuracy: 1.0000\n",
      "Epoch 78/200\n",
      "8006/8006 [==============================] - 11s 1ms/step - loss: 1.4323e-04 - accuracy: 1.0000\n",
      "Epoch 79/200\n",
      "8006/8006 [==============================] - 11s 1ms/step - loss: 2.1222e-04 - accuracy: 1.0000\n",
      "Epoch 80/200\n",
      "8006/8006 [==============================] - 10s 1ms/step - loss: 1.1202e-04 - accuracy: 1.0000\n",
      "Epoch 81/200\n",
      "8006/8006 [==============================] - 10s 1ms/step - loss: 9.7964e-05 - accuracy: 1.0000\n",
      "Epoch 82/200\n",
      "8006/8006 [==============================] - 10s 1ms/step - loss: 8.4578e-05 - accuracy: 1.0000\n",
      "Epoch 83/200\n",
      "8006/8006 [==============================] - 10s 1ms/step - loss: 1.5131e-04 - accuracy: 1.0000\n",
      "Epoch 84/200\n",
      "8006/8006 [==============================] - 10s 1ms/step - loss: 9.8626e-05 - accuracy: 1.0000\n",
      "Epoch 85/200\n",
      "8006/8006 [==============================] - 11s 1ms/step - loss: 8.7258e-05 - accuracy: 1.0000\n",
      "Epoch 86/200\n",
      "8006/8006 [==============================] - 11s 1ms/step - loss: 1.3632e-04 - accuracy: 1.0000\n",
      "Epoch 87/200\n",
      "8006/8006 [==============================] - 12s 1ms/step - loss: 8.1254e-05 - accuracy: 1.0000\n",
      "Epoch 88/200\n",
      "8006/8006 [==============================] - 12s 1ms/step - loss: 1.2781e-04 - accuracy: 1.0000\n",
      "Epoch 89/200\n",
      "8006/8006 [==============================] - 10s 1ms/step - loss: 6.2980e-05 - accuracy: 1.0000\n",
      "Epoch 90/200\n",
      "8006/8006 [==============================] - 10s 1ms/step - loss: 9.2454e-05 - accuracy: 1.0000\n",
      "Epoch 91/200\n",
      "8006/8006 [==============================] - 10s 1ms/step - loss: 1.1567e-04 - accuracy: 1.0000\n",
      "Epoch 92/200\n",
      "8006/8006 [==============================] - 10s 1ms/step - loss: 7.2523e-05 - accuracy: 1.0000\n",
      "Epoch 93/200\n",
      "8006/8006 [==============================] - 10s 1ms/step - loss: 1.0469e-04 - accuracy: 1.0000\n",
      "Epoch 94/200\n",
      "8006/8006 [==============================] - 10s 1ms/step - loss: 1.0133e-04 - accuracy: 1.0000\n",
      "Epoch 95/200\n",
      "8006/8006 [==============================] - 10s 1ms/step - loss: 6.3749e-05 - accuracy: 1.0000\n",
      "Epoch 96/200\n",
      "8006/8006 [==============================] - 10s 1ms/step - loss: 1.6722e-04 - accuracy: 1.0000\n",
      "Epoch 97/200\n",
      "8006/8006 [==============================] - 10s 1ms/step - loss: 9.0540e-05 - accuracy: 1.0000\n",
      "Epoch 98/200\n",
      "8006/8006 [==============================] - 10s 1ms/step - loss: 1.3486e-04 - accuracy: 1.0000\n",
      "Epoch 99/200\n",
      "8006/8006 [==============================] - 10s 1ms/step - loss: 9.8809e-05 - accuracy: 1.0000\n",
      "Epoch 100/200\n",
      "8006/8006 [==============================] - 10s 1ms/step - loss: 5.4787e-05 - accuracy: 1.0000\n",
      "Epoch 101/200\n",
      "8006/8006 [==============================] - 10s 1ms/step - loss: 2.0150e-04 - accuracy: 1.0000\n",
      "Epoch 102/200\n",
      "8006/8006 [==============================] - 10s 1ms/step - loss: 1.3522e-04 - accuracy: 1.0000\n",
      "Epoch 103/200\n",
      "8006/8006 [==============================] - 11s 1ms/step - loss: 6.7568e-05 - accuracy: 1.0000\n",
      "Epoch 104/200\n",
      "8006/8006 [==============================] - 12s 1ms/step - loss: 6.3232e-05 - accuracy: 1.0000\n",
      "Epoch 105/200\n",
      "8006/8006 [==============================] - 12s 1ms/step - loss: 6.7651e-05 - accuracy: 1.0000\n",
      "Epoch 106/200\n",
      "8006/8006 [==============================] - 12s 2ms/step - loss: 1.2352e-04 - accuracy: 1.0000\n",
      "Epoch 107/200\n",
      "8006/8006 [==============================] - 12s 1ms/step - loss: 9.4453e-05 - accuracy: 1.0000\n",
      "Epoch 108/200\n",
      "8006/8006 [==============================] - 12s 1ms/step - loss: 1.1136e-04 - accuracy: 1.0000\n",
      "Epoch 109/200\n",
      "8006/8006 [==============================] - 12s 1ms/step - loss: 1.0080e-04 - accuracy: 1.0000\n",
      "Epoch 110/200\n",
      "8006/8006 [==============================] - 12s 1ms/step - loss: 6.4263e-05 - accuracy: 1.0000\n",
      "Epoch 111/200\n",
      "8006/8006 [==============================] - 12s 1ms/step - loss: 6.8656e-05 - accuracy: 1.0000\n",
      "Epoch 112/200\n",
      "8006/8006 [==============================] - 12s 2ms/step - loss: 1.1947e-04 - accuracy: 1.0000\n",
      "Epoch 113/200\n",
      "8006/8006 [==============================] - 14s 2ms/step - loss: 9.6942e-05 - accuracy: 1.0000\n",
      "Epoch 114/200\n",
      "8006/8006 [==============================] - 12s 2ms/step - loss: 5.6908e-05 - accuracy: 1.0000\n",
      "Epoch 115/200\n",
      "8006/8006 [==============================] - 12s 1ms/step - loss: 7.3129e-05 - accuracy: 1.0000\n",
      "Epoch 116/200\n",
      "8006/8006 [==============================] - 12s 2ms/step - loss: 6.6595e-05 - accuracy: 1.0000\n",
      "Epoch 117/200\n",
      "8006/8006 [==============================] - 12s 1ms/step - loss: 8.1105e-05 - accuracy: 1.0000\n",
      "Epoch 118/200\n",
      "8006/8006 [==============================] - 12s 1ms/step - loss: 1.2119e-04 - accuracy: 1.0000\n",
      "Epoch 119/200\n",
      "8006/8006 [==============================] - 11s 1ms/step - loss: 9.2425e-05 - accuracy: 1.0000\n",
      "Epoch 120/200\n",
      "8006/8006 [==============================] - 12s 1ms/step - loss: 6.0845e-05 - accuracy: 1.0000\n",
      "Epoch 121/200\n",
      "8006/8006 [==============================] - 11s 1ms/step - loss: 6.4790e-05 - accuracy: 1.0000\n",
      "Epoch 122/200\n",
      "8006/8006 [==============================] - 12s 2ms/step - loss: 5.3014e-05 - accuracy: 1.0000\n",
      "Epoch 123/200\n",
      "8006/8006 [==============================] - 12s 2ms/step - loss: 1.2998e-04 - accuracy: 1.0000\n",
      "Epoch 124/200\n",
      "8006/8006 [==============================] - 12s 1ms/step - loss: 7.2511e-05 - accuracy: 1.0000\n",
      "Epoch 125/200\n",
      "8006/8006 [==============================] - 12s 2ms/step - loss: 7.2416e-05 - accuracy: 1.0000\n",
      "Epoch 126/200\n",
      "8006/8006 [==============================] - 12s 2ms/step - loss: 5.9847e-05 - accuracy: 1.0000\n",
      "Epoch 127/200\n",
      "8006/8006 [==============================] - 12s 1ms/step - loss: 8.6983e-05 - accuracy: 1.0000\n",
      "Epoch 128/200\n",
      "8006/8006 [==============================] - 10s 1ms/step - loss: 7.9390e-05 - accuracy: 1.0000\n",
      "Epoch 129/200\n",
      "8006/8006 [==============================] - 10s 1ms/step - loss: 7.2773e-05 - accuracy: 1.0000\n",
      "Epoch 130/200\n",
      "8006/8006 [==============================] - 10s 1ms/step - loss: 7.4581e-05 - accuracy: 1.0000\n",
      "Epoch 131/200\n",
      "8006/8006 [==============================] - 10s 1ms/step - loss: 1.0436e-04 - accuracy: 1.0000\n",
      "Epoch 132/200\n",
      "8006/8006 [==============================] - 11s 1ms/step - loss: 6.4277e-05 - accuracy: 1.0000\n",
      "Epoch 133/200\n",
      "8006/8006 [==============================] - 12s 2ms/step - loss: 5.3634e-05 - accuracy: 1.0000\n",
      "Epoch 134/200\n",
      "8006/8006 [==============================] - 12s 1ms/step - loss: 4.9489e-05 - accuracy: 1.0000\n",
      "Epoch 135/200\n",
      "8006/8006 [==============================] - 12s 2ms/step - loss: 1.2938e-04 - accuracy: 1.0000\n",
      "Epoch 136/200\n",
      "8006/8006 [==============================] - 12s 2ms/step - loss: 5.1872e-05 - accuracy: 1.0000\n",
      "Epoch 137/200\n",
      "8006/8006 [==============================] - 12s 2ms/step - loss: 6.7137e-05 - accuracy: 1.0000\n",
      "Epoch 138/200\n",
      "8006/8006 [==============================] - 12s 1ms/step - loss: 6.3251e-05 - accuracy: 1.0000\n",
      "Epoch 139/200\n",
      "8006/8006 [==============================] - 12s 2ms/step - loss: 8.5356e-05 - accuracy: 1.0000\n",
      "Epoch 140/200\n",
      "8006/8006 [==============================] - 12s 1ms/step - loss: 4.4582e-05 - accuracy: 1.0000\n",
      "Epoch 141/200\n",
      "8006/8006 [==============================] - 12s 2ms/step - loss: 2.1679e-05 - accuracy: 1.0000\n",
      "Epoch 142/200\n",
      "8006/8006 [==============================] - 12s 1ms/step - loss: 2.7854e-05 - accuracy: 1.0000\n",
      "Epoch 143/200\n",
      "8006/8006 [==============================] - 12s 1ms/step - loss: 5.9572e-05 - accuracy: 1.0000\n",
      "Epoch 144/200\n",
      "8006/8006 [==============================] - 12s 1ms/step - loss: 2.2323e-05 - accuracy: 1.0000\n",
      "Epoch 145/200\n",
      "8006/8006 [==============================] - 12s 2ms/step - loss: 3.4002e-05 - accuracy: 1.0000\n",
      "Epoch 146/200\n",
      "8006/8006 [==============================] - 12s 2ms/step - loss: 2.1806e-05 - accuracy: 1.0000\n",
      "Epoch 147/200\n",
      "8006/8006 [==============================] - 12s 2ms/step - loss: 2.1725e-05 - accuracy: 1.0000\n",
      "Epoch 148/200\n",
      "8006/8006 [==============================] - 12s 2ms/step - loss: 2.1545e-05 - accuracy: 1.0000\n",
      "Epoch 149/200\n",
      "8006/8006 [==============================] - 12s 1ms/step - loss: 8.1701e-05 - accuracy: 1.0000\n",
      "Epoch 150/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8006/8006 [==============================] - 11s 1ms/step - loss: 7.5030e-05 - accuracy: 1.0000\n",
      "Epoch 151/200\n",
      "8006/8006 [==============================] - 11s 1ms/step - loss: 7.4027e-05 - accuracy: 1.0000\n",
      "Epoch 152/200\n",
      "8006/8006 [==============================] - 11s 1ms/step - loss: 4.5123e-05 - accuracy: 1.0000\n",
      "Epoch 153/200\n",
      "8006/8006 [==============================] - 11s 1ms/step - loss: 4.6796e-05 - accuracy: 1.0000\n",
      "Epoch 154/200\n",
      "8006/8006 [==============================] - 11s 1ms/step - loss: 3.1601e-05 - accuracy: 1.0000\n",
      "Epoch 155/200\n",
      "8006/8006 [==============================] - 11s 1ms/step - loss: 2.9927e-05 - accuracy: 1.0000\n",
      "Epoch 156/200\n",
      "8006/8006 [==============================] - 11s 1ms/step - loss: 5.9313e-05 - accuracy: 1.0000\n",
      "Epoch 157/200\n",
      "8006/8006 [==============================] - 13s 2ms/step - loss: 1.2720e-04 - accuracy: 1.0000\n",
      "Epoch 158/200\n",
      "8006/8006 [==============================] - 13s 2ms/step - loss: 5.7632e-05 - accuracy: 1.0000\n",
      "Epoch 159/200\n",
      "8006/8006 [==============================] - 12s 1ms/step - loss: 7.3294e-05 - accuracy: 1.0000\n",
      "Epoch 160/200\n",
      "8006/8006 [==============================] - 12s 1ms/step - loss: 1.1710e-05 - accuracy: 1.0000\n",
      "Epoch 161/200\n",
      "8006/8006 [==============================] - 12s 1ms/step - loss: 9.9354e-05 - accuracy: 1.0000\n",
      "Epoch 162/200\n",
      "8006/8006 [==============================] - 12s 1ms/step - loss: 4.9426e-05 - accuracy: 1.0000\n",
      "Epoch 163/200\n",
      "8006/8006 [==============================] - 12s 2ms/step - loss: 2.4924e-05 - accuracy: 1.0000\n",
      "Epoch 164/200\n",
      "8006/8006 [==============================] - 13s 2ms/step - loss: 2.7780e-05 - accuracy: 1.0000\n",
      "Epoch 165/200\n",
      "8006/8006 [==============================] - 11s 1ms/step - loss: 2.4794e-05 - accuracy: 1.0000\n",
      "Epoch 166/200\n",
      "8006/8006 [==============================] - 11s 1ms/step - loss: 3.7267e-05 - accuracy: 1.0000\n",
      "Epoch 167/200\n",
      "8006/8006 [==============================] - 12s 2ms/step - loss: 5.0724e-05 - accuracy: 1.0000\n",
      "Epoch 168/200\n",
      "8006/8006 [==============================] - 12s 1ms/step - loss: 6.8966e-05 - accuracy: 1.0000\n",
      "Epoch 169/200\n",
      "8006/8006 [==============================] - 12s 1ms/step - loss: 4.3005e-05 - accuracy: 1.0000\n",
      "Epoch 170/200\n",
      "8006/8006 [==============================] - 12s 1ms/step - loss: 2.2480e-05 - accuracy: 1.0000\n",
      "Epoch 171/200\n",
      "8006/8006 [==============================] - 12s 1ms/step - loss: 3.8420e-05 - accuracy: 1.0000\n",
      "Epoch 172/200\n",
      "8006/8006 [==============================] - 12s 1ms/step - loss: 1.6716e-05 - accuracy: 1.0000\n",
      "Epoch 173/200\n",
      "8006/8006 [==============================] - 12s 1ms/step - loss: 2.6182e-05 - accuracy: 1.0000\n",
      "Epoch 174/200\n",
      "8006/8006 [==============================] - 12s 1ms/step - loss: 1.8807e-05 - accuracy: 1.0000\n",
      "Epoch 175/200\n",
      "8006/8006 [==============================] - 12s 1ms/step - loss: 8.2200e-05 - accuracy: 1.0000\n",
      "Epoch 176/200\n",
      "8006/8006 [==============================] - 13s 2ms/step - loss: 1.4491e-05 - accuracy: 1.0000\n",
      "Epoch 177/200\n",
      "8006/8006 [==============================] - 14s 2ms/step - loss: 2.7885e-05 - accuracy: 1.0000\n",
      "Epoch 178/200\n",
      "8006/8006 [==============================] - 13s 2ms/step - loss: 4.1855e-05 - accuracy: 1.0000\n",
      "Epoch 179/200\n",
      "8006/8006 [==============================] - 14s 2ms/step - loss: 3.4579e-05 - accuracy: 1.0000\n",
      "Epoch 180/200\n",
      "8006/8006 [==============================] - 14s 2ms/step - loss: 4.4785e-05 - accuracy: 1.0000\n",
      "Epoch 181/200\n",
      "8006/8006 [==============================] - 13s 2ms/step - loss: 1.7725e-05 - accuracy: 1.0000\n",
      "Epoch 182/200\n",
      "8006/8006 [==============================] - 13s 2ms/step - loss: 3.0639e-05 - accuracy: 1.0000\n",
      "Epoch 183/200\n",
      "8006/8006 [==============================] - 13s 2ms/step - loss: 8.6832e-05 - accuracy: 1.0000\n",
      "Epoch 184/200\n",
      "8006/8006 [==============================] - 13s 2ms/step - loss: 3.9395e-05 - accuracy: 1.0000\n",
      "Epoch 185/200\n",
      "8006/8006 [==============================] - 13s 2ms/step - loss: 4.1712e-05 - accuracy: 1.0000\n",
      "Epoch 186/200\n",
      "8006/8006 [==============================] - 14s 2ms/step - loss: 3.6477e-05 - accuracy: 1.0000\n",
      "Epoch 187/200\n",
      "8006/8006 [==============================] - 12s 2ms/step - loss: 5.9862e-05 - accuracy: 1.0000\n",
      "Epoch 188/200\n",
      "8006/8006 [==============================] - 12s 1ms/step - loss: 4.0786e-05 - accuracy: 1.0000\n",
      "Epoch 189/200\n",
      "8006/8006 [==============================] - 12s 1ms/step - loss: 6.9961e-05 - accuracy: 1.0000\n",
      "Epoch 190/200\n",
      "8006/8006 [==============================] - 12s 1ms/step - loss: 4.0349e-05 - accuracy: 1.0000\n",
      "Epoch 191/200\n",
      "8006/8006 [==============================] - 12s 1ms/step - loss: 8.8407e-05 - accuracy: 1.0000\n",
      "Epoch 192/200\n",
      "8006/8006 [==============================] - 12s 1ms/step - loss: 4.7129e-05 - accuracy: 1.0000\n",
      "Epoch 193/200\n",
      "8006/8006 [==============================] - 12s 1ms/step - loss: 3.8785e-05 - accuracy: 1.0000\n",
      "Epoch 194/200\n",
      "8006/8006 [==============================] - 12s 1ms/step - loss: 5.1963e-05 - accuracy: 1.0000\n",
      "Epoch 195/200\n",
      "8006/8006 [==============================] - 12s 1ms/step - loss: 3.0666e-05 - accuracy: 1.0000\n",
      "Epoch 196/200\n",
      "8006/8006 [==============================] - 13s 2ms/step - loss: 3.9840e-05 - accuracy: 1.0000\n",
      "Epoch 197/200\n",
      "8006/8006 [==============================] - 11s 1ms/step - loss: 3.6405e-05 - accuracy: 1.0000\n",
      "Epoch 198/200\n",
      "8006/8006 [==============================] - 12s 1ms/step - loss: 2.6035e-05 - accuracy: 1.0000\n",
      "Epoch 199/200\n",
      "8006/8006 [==============================] - 12s 1ms/step - loss: 4.4129e-05 - accuracy: 1.0000\n",
      "Epoch 200/200\n",
      "8006/8006 [==============================] - 12s 1ms/step - loss: 4.0495e-05 - accuracy: 1.0000\n",
      "model created\n"
     ]
    }
   ],
   "source": [
    "# Create model - 3 layers. First layer 128 neurons, second layer 64 neurons and 3rd output layer contains number of neurons\n",
    "# equal to number of intents to predict output intent with softmax\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape=(len(train_x[0]),), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(len(train_y[0]), activation='softmax'))\n",
    "# Compile model. Stochastic gradient descent with Nesterov accelerated gradient gives good results for this model\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "#fitting and saving the model \n",
    "hist = model.fit(np.array(train_x), np.array(train_y), epochs=200, batch_size=5, verbose=1)\n",
    "model.save('chatbot_model.h5', hist)\n",
    "print(\"model created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b16d02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('intents.json', 'w') as fp:\n",
    "    json.dump(intents, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639b7026",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
